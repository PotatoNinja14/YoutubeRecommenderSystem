{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98f9a52d",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5173d67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# api_key = 'AIzaSyD72ZqGlZ_yp9vg4r55m06vbfNf_kj62uk'\n",
    "# channel_ids = ['UCX6OQ3DkcsbYNE6H8uQQuVA', 'UCYO_jab_esuFRV4b17AJtAw', 'UC7_YxT-KID8kRbqZo7MyscQ', 'UCo_IB5145EVNcf8hw1Kku7w', 'UC-lHJZR3Gqxm24_Vd_AJ5Yw', 'UCX6b17PVsYBQ0ip5gyeme-Q', 'UC7_gcs09iThXybpVgjHZ_7g', 'UCZSNzBgFub_WWil6TOTYwAg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01dae53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade google-api-python-client\n",
    "# !pip install isodate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d136b931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import isodate\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from nltk.corpus import stopwords\n",
    "from IPython.display import display\n",
    "from nltk.tokenize import word_tokenize\n",
    "from googleapiclient.discovery import build\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7405b303",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# api_service_name = \"youtube\"\n",
    "# api_version = \"v3\"\n",
    "\n",
    "# youtube = build(\n",
    "#     api_service_name, api_version, developerKey = api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19547e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_channel_stats(youtube, channel_ids):\n",
    "    \n",
    "#     all_data = []\n",
    "#     request = youtube.channels().list(\n",
    "#         part = \"snippet,contentDetails,statistics\",\n",
    "#         id = ','.join(channel_ids)\n",
    "#     )\n",
    "#     response = request.execute()\n",
    "\n",
    "#     for item in response['items']:\n",
    "#         data = {'channelName': item['snippet']['title'],\n",
    "#                 'playlistId': item['contentDetails']['relatedPlaylists']['uploads']\n",
    "#         }\n",
    "#         all_data.append(data)\n",
    "        \n",
    "#     return(pd.DataFrame(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86f65612",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# channel_stats = get_channel_stats(youtube, channel_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fd8b13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel_stats.rename(columns = {'totalViews':'totalVideos'}, inplace = True)\n",
    "# channel_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba94aa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# playlist_ids = pd.DataFrame(channel_stats['playlistId'].astype(str), columns=['playlistId'])\n",
    "# print(playlist_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd79ecbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# playlist_ids = pd.DataFrame(channel_stats['playlistId'].astype(str), columns=['playlistId'])\n",
    "\n",
    "\n",
    "# def get_video_ids(youtube, playlist_ids):\n",
    "\n",
    "#     video_ids = [[] for _ in range(len(playlist_ids))]\n",
    "#     for i in range(len(playlist_ids)):\n",
    "#         request = youtube.playlistItems().list(\n",
    "#             part = \"snippet,contentDetails\",\n",
    "#             playlistId = playlist_ids.iloc[i]['playlistId'],\n",
    "#             maxResults = 50\n",
    "#         )\n",
    "#         response = request.execute()\n",
    "#         for item in response['items']:\n",
    "#             video_ids[i].append(item['contentDetails']['videoId'])\n",
    "\n",
    "#         next_page_token = response.get('nextPageToken')\n",
    "#         while next_page_token is not None:\n",
    "#             request = youtube.playlistItems().list(\n",
    "#                         part ='contentDetails',\n",
    "#                         playlistId = playlist_ids.iloc[i]['playlistId'],\n",
    "#                         maxResults = 50,\n",
    "#                         pageToken = next_page_token)\n",
    "#             response = request.execute()\n",
    "\n",
    "#             for item in response['items']:\n",
    "#                 video_ids[i].append(item['contentDetails']['videoId'])\n",
    "\n",
    "#             next_page_token = response.get('nextPageToken')\n",
    "        \n",
    "#     return video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb19ddfc",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i in range(len(channel_ids)):\n",
    "#     video_ids = get_video_ids(youtube, playlist_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c2a374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(channel_ids)):\n",
    "#     print(len(video_ids[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a08d4193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_video_details(youtube, video_ids):\n",
    "\n",
    "#     all_video_info = []\n",
    "    \n",
    "#     for i in range(0, len(video_ids), 50):\n",
    "#         request = youtube.videos().list(\n",
    "#             part=\"snippet,contentDetails,statistics\",\n",
    "#             id=','.join(video_ids[i:i+50])\n",
    "#         )\n",
    "#         response = request.execute() \n",
    "\n",
    "#         for video in response['items']:\n",
    "#             stats_to_keep = {'snippet': ['channelTitle', 'title', 'description', 'tags', 'publishedAt'],\n",
    "#                              'statistics': ['viewCount', 'likeCount', 'favouriteCount', 'commentCount'],\n",
    "#                              'contentDetails': ['duration', 'definition', 'caption']\n",
    "#                             }\n",
    "#             video_info = {}\n",
    "#             video_info['video_id'] = video['id']\n",
    "\n",
    "#             for k in stats_to_keep.keys():\n",
    "#                 for v in stats_to_keep[k]:\n",
    "#                     try:\n",
    "#                         video_info[v] = video[k][v]\n",
    "#                     except:\n",
    "#                         video_info[v] = None\n",
    "\n",
    "#             all_video_info.append(video_info)\n",
    "    \n",
    "#     return pd.DataFrame(all_video_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6654d117",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# video_df2 = pd.DataFrame()\n",
    "# for i in range(0, 8):\n",
    "#     video_dff = (get_video_details(youtube, video_ids[i]))\n",
    "#     video_df2 = pd.concat([video_df2, video_dff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3874419e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# video_df2.to_excel(\"Youtube_Orig_Channel_Data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0419ca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_df2 = pd.read_excel(\"Youtube_Orig_Channel_Data.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2218c26",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05864ae3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# video_df2.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c728522",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# video_df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b57e2314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_useful_words(text):\n",
    "#     words = word_tokenize(text)\n",
    "#     useful_words = [word.lower() for word in words if word.lower() not in stopwords.words('english')]\n",
    "#     return useful_words\n",
    "\n",
    "# def generate_tags(df):\n",
    "#     for i in range(len(df)):\n",
    "#         if str(df.iloc[i]['tags']) == 'nan':\n",
    "#             title_words = extract_useful_words(df.iloc[i]['title'])\n",
    "#             combined_words = title_words + [df.iloc[i]['channelTitle']]\n",
    "#             combined_words = list(set(combined_words))\n",
    "#             df.loc[i, 'tags'] = str(combined_words)\n",
    "#             print(df.loc[i, 'tags'])\n",
    "\n",
    "# generate_tags(video_df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38fd0063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_df2['durationSecs'] = video_df2['duration'].apply(lambda x: isodate.parse_duration(x))\n",
    "# video_df2['durationSecs'] = video_df2['durationSecs'].astype('timedelta64[s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "949df020",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# videos_df = video_df2.drop(['Unnamed: 0','video_id', 'description', 'duration', 'publishedAt'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "601bdb6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def clean_titles(title):\n",
    "#     return re.sub(\"[^a-zA-Z0-9 ]\", \"\", title)\n",
    "# videos_df[\"title\"] = videos_df[\"title\"].apply(clean_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de62fba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel_stats.to_excel(\"Youtube_Channel_Data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c47760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# videos_df.to_excel(\"Tag_Duration_Data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34a5d529",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_df = pd.read_excel(\"Tag_Duration_Data.xlsx\", usecols=['channelTitle', 'title', 'tags', 'durationSecs'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1633db94",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_df.dropna(subset=['title'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "12cb829a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channelTitle</th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "      <th>durationSecs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3688</th>\n",
       "      <td>PewDiePie</td>\n",
       "      <td>HIPSTER PIGEON FITS  ScribbleNauts Unlimited  ...</td>\n",
       "      <td>['pewdiepie', 'pewdie', 'lets', 'play', 'let´s...</td>\n",
       "      <td>1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7755</th>\n",
       "      <td>Netflix India</td>\n",
       "      <td>Can They Survive The Fame Game  Mythpat aishmr...</td>\n",
       "      <td>['netflix india', 'netflix', 'netflix shows', ...</td>\n",
       "      <td>967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17766</th>\n",
       "      <td>CrashCourse</td>\n",
       "      <td>OCD and Anxiety Disorders Crash Course Psychol...</td>\n",
       "      <td>['Anxiety Disorder (Disease Or Medical Conditi...</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7459</th>\n",
       "      <td>Netflix India</td>\n",
       "      <td>Vaashi  Official Trailer  Tovino Thomas Keerth...</td>\n",
       "      <td>['netflix india', 'netflix', 'netflix shows', ...</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7352</th>\n",
       "      <td>Netflix India</td>\n",
       "      <td>Taapsee Pannus Cricket Dilemma  Taapsee Pannu ...</td>\n",
       "      <td>['netflix india', 'netflix', 'netflix shows']</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8937</th>\n",
       "      <td>Netflix India</td>\n",
       "      <td>Emily In Paris  Hindi Trailer  Netflix India</td>\n",
       "      <td>['netflix india', 'netflix', 'netflix shows', ...</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16193</th>\n",
       "      <td>Markiplier</td>\n",
       "      <td>Lets Play Skyrim  Part 19  DOWN INTO THE DEPTHS</td>\n",
       "      <td>[\"Let's Play Skyrim\", 'Skyrim Mods', 'Skyrim G...</td>\n",
       "      <td>1830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6514</th>\n",
       "      <td>Netflix India</td>\n",
       "      <td>Alia Bhatt  Siddharth Malhotra go on the CUTES...</td>\n",
       "      <td>['Alia Bhatt', 'Shefali shah', 'alia bhatt dar...</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9955</th>\n",
       "      <td>Netflix India</td>\n",
       "      <td>To All The Boys Ive Loved Before  Main Trailer...</td>\n",
       "      <td>['high school', 'movie', 'janel parrish', 'fml...</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12993</th>\n",
       "      <td>Markiplier</td>\n",
       "      <td>Oxygen Not Included  Part 10  THE SADDEST EPIS...</td>\n",
       "      <td>['markiplier', 'oxygen not included', 'game', ...</td>\n",
       "      <td>914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18038 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        channelTitle                                              title  \\\n",
       "3688       PewDiePie  HIPSTER PIGEON FITS  ScribbleNauts Unlimited  ...   \n",
       "7755   Netflix India  Can They Survive The Fame Game  Mythpat aishmr...   \n",
       "17766    CrashCourse  OCD and Anxiety Disorders Crash Course Psychol...   \n",
       "7459   Netflix India  Vaashi  Official Trailer  Tovino Thomas Keerth...   \n",
       "7352   Netflix India  Taapsee Pannus Cricket Dilemma  Taapsee Pannu ...   \n",
       "...              ...                                                ...   \n",
       "8937   Netflix India       Emily In Paris  Hindi Trailer  Netflix India   \n",
       "16193     Markiplier    Lets Play Skyrim  Part 19  DOWN INTO THE DEPTHS   \n",
       "6514   Netflix India  Alia Bhatt  Siddharth Malhotra go on the CUTES...   \n",
       "9955   Netflix India  To All The Boys Ive Loved Before  Main Trailer...   \n",
       "12993     Markiplier  Oxygen Not Included  Part 10  THE SADDEST EPIS...   \n",
       "\n",
       "                                                    tags  durationSecs  \n",
       "3688   ['pewdiepie', 'pewdie', 'lets', 'play', 'let´s...          1033  \n",
       "7755   ['netflix india', 'netflix', 'netflix shows', ...           967  \n",
       "17766  ['Anxiety Disorder (Disease Or Medical Conditi...           692  \n",
       "7459   ['netflix india', 'netflix', 'netflix shows', ...           104  \n",
       "7352       ['netflix india', 'netflix', 'netflix shows']           152  \n",
       "...                                                  ...           ...  \n",
       "8937   ['netflix india', 'netflix', 'netflix shows', ...           110  \n",
       "16193  [\"Let's Play Skyrim\", 'Skyrim Mods', 'Skyrim G...          1830  \n",
       "6514   ['Alia Bhatt', 'Shefali shah', 'alia bhatt dar...           137  \n",
       "9955   ['high school', 'movie', 'janel parrish', 'fml...           123  \n",
       "12993  ['markiplier', 'oxygen not included', 'game', ...           914  \n",
       "\n",
       "[18038 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v =videos_df.sample(frac=1)\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349128a7",
   "metadata": {},
   "source": [
    "# Building the Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a24e370",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "tfidf = vectorizer.fit_transform(videos_df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "688c30e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 3\u001b[0m      data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('data.pickle', 'rb') as f:\n",
    "     data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb5a854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(title):\n",
    "    query_vec = vectorizer.transform([title])\n",
    "    similarity = cosine_similarity(query_vec, tfidf).flatten()\n",
    "    indices = np.argpartition(similarity, -5)[-5:] \n",
    "    results = videos_df.iloc[indices].iloc[::-1]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66431c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "# tfidf_tags = tag_vectorizer.fit_transform(videos_df['tags'])\n",
    "\n",
    "def find_similar_videos(title):\n",
    "    query_vec = vectorizer.transform([title])\n",
    "    title_similarity = cosine_similarity(query_vec, tfidf).flatten()\n",
    "    input_tags = videos_df[videos_df['title'] == title]['tags'].values[0]\n",
    "    input_tags_vec = tag_vectorizer.transform([input_tags])\n",
    "    tag_similarity = cosine_similarity(input_tags_vec, data).flatten()\n",
    "    combined_similarity = 0.5 * title_similarity + 0.5 * tag_similarity\n",
    "    indices = np.argpartition(combined_similarity, -5)[-10:]\n",
    "    indices = indices[np.argsort(combined_similarity[indices])][::-1]\n",
    "    results = videos_df.iloc[indices][['channelTitle', 'title']].iloc[::-1]\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5855d32a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b8d9d8165e42e2b2bf85a51c7ad783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Video Title:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68978b1ab2994f608457d7357927af36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "video_input = widgets.Text(\n",
    "    value='',\n",
    "    description='Video Title:',\n",
    "    disabled=False\n",
    ")\n",
    "video_list = widgets.Output()\n",
    "\n",
    "def on_type(data):\n",
    "    with video_list:\n",
    "        video_list.clear_output()\n",
    "        title = data[\"new\"]\n",
    "        if len(title) > 5:\n",
    "            result = search(title)\n",
    "            vtitle = result.iloc[0][\"title\"]    \n",
    "            display(find_similar_videos(vtitle))\n",
    "\n",
    "video_input.observe(on_type, names='value')\n",
    "\n",
    "\n",
    "display(video_input, video_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ffc01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import TruncatedSVD\n",
    "# from scipy.sparse import lil_matrix\n",
    "\n",
    "# tfidf_tags = vectorizer.fit_transform(videos_df['tags'])\n",
    "# n_components = 1  \n",
    "# svd = TruncatedSVD(n_components=n_components)\n",
    "# tfidf_matrix_svd = svd.fit(tfidf_tags).transform(tfidf_tags)\n",
    "\n",
    "# duration_scaled = videos_df['durationSecs'] / videos_df['durationSecs'].max()\n",
    "\n",
    "# tag_weight = 0.8\n",
    "# duration_weight = 1 - tag_weight\n",
    "\n",
    "# weighted_features = (tag_weight * tfidf_matrix_svd) + (duration_weight * lil_matrix(duration_scaled).T)\n",
    "\n",
    "# batch_size = 2000\n",
    "\n",
    "# num_videos = len(videos_df)\n",
    "# similarity_matrix = lil_matrix((num_videos, num_videos))\n",
    "\n",
    "# for i in range(0, num_videos, batch_size):\n",
    "#     start_idx = i\n",
    "#     end_idx = min(i + batch_size, num_videos)\n",
    "#     similarity_batch = cosine_similarity(np.asarray(weighted_features)[start_idx:end_idx], np.asarray(weighted_features))\n",
    "#     similarity_matrix[start_idx:end_idx] = similarity_batch\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
